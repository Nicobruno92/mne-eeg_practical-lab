{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG practical lab - Neurociencias & IA\n",
    "#### Tutores: Mg. Nicolás Bruno y Mg. Tomás D'Amelio\n",
    "\n",
    "## Consigna\n",
    "En la clase de hoy van a tener que realizar  el **análisis desde cero de un set de datos de EEG** hasta obtener resultados reportables.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "El set de datos lo van a poder descargar de acá: \n",
    "\n",
    "https://openneuro.org/datasets/ds003690/versions/1.0.0\n",
    "\n",
    "El *dataset* contiene datos de 75 participantes e incluye señales de EEG, ECG y pupilometría mientras estos participantes realizan:\n",
    "- una tarea pasiva\n",
    "- una tarea simple de tiempos de reacción\n",
    "- una tarea de Go/No-go.\n",
    "  \n",
    "Nosotros nos vamos a enfocar en la tarea Go/No-go.\n",
    "En esta tarea, dependiendo la frecuencia de un determinado estimulo sonoro que se le presentaba, el participante tenía que apretar un botón (Go) o no apretar un botón (No-Go). El 80 % de los ensayos eran *ensayos cue-go*, mientras que el 20% eran *ensayos cue-no-go.*\n",
    "\n",
    "\n",
    "## MNE python\n",
    "\n",
    "Para poder realizar prácticamente todos los análisis van a tener que usar la librería de Python MNE, destinada al análisis de EEG. [ACÁ](https://mne.tools/stable/index.html) van a poder encontrar todo la documentación de esta librería, con sus funciones y qué hacen las mismas. También van a encontrar tutoriales que explican paso a paso cómo hacer ciertas procedimientos de análisis de datos.\n",
    "\n",
    "\n",
    "## Resolución\n",
    "Este notebook va ir guiandolos en qué tienen que ir haciendo durante el practical. Van a encontrar celdas de texto que los introducen un poco a lo que tienen que hacer y celdas con código incompleto (e.g. \"...\") que ustedes van a tener que completar. En algunos casos directamente encontrarán celdas vacías para que sean completadas en su totalidad por ustedes.\n",
    "\n",
    "Cualquier consulta pueden consultarnos a nuestros mails:\n",
    "- nicobruno92@gmail.com\n",
    "- dameliotomas@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos las librerias que vamos a usar ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta linea es para que los gráficos aparezcan fuera de jupyter ya que los gráficos de MNE  son interactivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas librerías que podrían resultar de utilidad.\\\n",
    "Recuerden que si no tienen alguna de la siguientes librerias pueden bajarlas desde \"Anaconda Prompt (anaconda3)\", utilizando el comando \"pip install NOMBRE_DE_LIBRERIA\".\\\n",
    "E.g. pip install pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento\n",
    "Lo primero que vamos a hacer es preprocesar los datos de cada sujeto. Para eso nosotros armamos un _pipeline_ (serie de pasos) clásico de preprocesamiento de EEG parecido al que vieron durante la clase de EEG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar la data en BIDS format\n",
    "\n",
    "Vamos a descargar la data de una base de datos llamada Open Neuro que es de Open Access.\n",
    "El dataset que vamos a usar es el siguiente:\n",
    "\n",
    "https://openneuro.org/datasets/ds003690/download\n",
    "\n",
    "Este dataset se encuentra en un formato que se llama Brain Imaging Data Structure (BIDS), que se utiliza para que todos estos datasets de acceso público se manejen de forma estandarizada, de forma tal que sea mas fácil compartir información y que otros la puedan utilizar.\n",
    "\n",
    "**Descargar el set de datos y asignar en la variable \"bids_root\" el path donde se encuentran tus datos descargados.**\n",
    "E.g. Si sus datos se encuentran en '/Users/dadam/data_practical_lab/' deberán ejecutar el sigueinte comando:\n",
    "\n",
    "bids_root = '/Users/dadam/data_practical_lab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completa con el path donde se encuentren tus datos descargados\n",
    "bids_root = '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería MNE-BIDS tiene una función llamada \"make_report()\" que resume la información del dataset sobre:\n",
    "\n",
    "a) Descripción general del set de datos (guardada en el archivo \"dataset_description.json\")\n",
    "\n",
    "b) Información de los participantes (guardada en el archivo \"participants.tsv file\")\n",
    "\n",
    "c) Información de los datos de EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_report(bids_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar BIDS data\n",
    "Acá van a tener que buscar la función de MNE para cargar/leer (_read_ en inglés) la data para el tipo de archivo que vamos a usar. \\\n",
    "El tipo de archivo en MNE se llama BIDS.\\\n",
    "Una vez identificada la función van a usarla para leer el archivo de un sujeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo nos va a interesar la data de EEG\n",
    "datatype = 'eeg'\n",
    "suffix = 'eeg'\n",
    "\n",
    "# Nombre que le vamos a poenr a la tarea (GO-NOGO)\n",
    "task = 'gonogo' \n",
    "\n",
    "# Los sujetos tenian 2 _runs_ por task pero solo vamos a usar el 1\n",
    "run = '1'\n",
    "\n",
    "# Sujeto que queremos utilizar\n",
    "# Vamos a empezar utilizando el 'sub-AB12'\n",
    "subject = 'AB12'\n",
    "\n",
    "bids_path = BIDSPath(subject=subject, task=task, run = run,\n",
    "                     suffix=suffix, datatype=datatype, \n",
    "                    root=bids_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bids_path) # display es como print pero se ve más lindo en jupyter :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Leer archivo BIDS</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Usar la funcion \"read_raw_bids\" de la libreria MNE bids</i></li>\n",
    "    <li> <i>Pasar \"bids_path\" como argumento de dicha función</i></li>\n",
    "    <li> <i>Asginar los datos leidos a la variable \"raw\"</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo crudo pasando el path que acabamos de crear al archivo\n",
    "raw = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seteamos montage según condiciones experimentales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino canales que no son de EEG\n",
    "raw = raw.drop_channels(['M1', 'M2', 'PO5', 'PO6', 'CB1', 'CB2', 'R-Dia-X-(mm)', 'R-Dia-Y-(mm)'])\n",
    "# Seteo el montage de acuerdo a las condiciones experimentales (en el trabajo usaron Biosemi de 64 canales)\n",
    "raw.set_montage('biosemi64')\n",
    "raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos a usar el método \"info\"  para ver un poco que hay adentro de nuestro archivo que acabamos de cargar.\n",
    "#### Esto nos va a decir cuántos canales tenemos y de qué tipo, los nombres de los canales, si ya tiene aplicado algun filtro, cual fue la frequencia de sampleo, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw.info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['sfreq']  # Para ver la frequencia de sampleo (i.e. cantidad de registros por segundo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['bads']  # Para ver si algun canal fue marcado como \"malo\" (i.e. defectuoso) por parte de los investigadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionar el nombre de los 10 primeros canales de nuestros datos.\\\n",
    "*Hint*: Utilizar el atributo `ch_names` de la clase Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionar la cantidad de canales en nuestros datos.\\\n",
    "\n",
    "*Hint*: Revisar la metadata que se puede obtener de `info` dentor de la clase Raw\n",
    "Ver https://mne.tools/stable/generated/mne.Info.html#mne.Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling la data\n",
    "\n",
    "El downsampling consiste en reducir la cantidad registros por segundo que queremos que tenga nuestra data. Esto lo hacemos para agilizar nuestros análisis ya que para lo que vamos a hacer no nos interesa que la frecuencia de sampleo sea tan alta.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>\"Downsamplear\" a la mitad de Hz (i.e. la mitad de la cantidad de puntos por segundo) en relación a la data orginal. Si no recuerdan cuánto era la frecuencia de sampleo. está en el método \"info\" bajo \"sfreq\"</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos a memroia (requeria para algunas operaciones)\n",
    "raw.load_data()  \n",
    "# Downsamplear la data a la mitad\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar la data cruda\n",
    "\n",
    "Es muy importante visualizar la data cruda para ver si hay algun canal cuya señal esté \"mala\"/ruidosa. Tómense unos minutos para inspeccionar visualmente los datos de este sujeto.\n",
    "\n",
    "MNE nos permite generar visualizaciones interactivas en donde uno puedo marcar los canales como \"malos\" (se ponen en gris) y cuando se cierra el _plot_ (apretando ESC) va a quedar guardado automaticamente ese canal como malo. \n",
    "\n",
    "_Disclaimer_: cuando creen un gráfico si o si van a tener que cerrarlo para poder seguir bien con el codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Ver si hay canales malos</li>\n",
    "    <li>Marcar canales malos (si lo hay)</li>\n",
    "    <li>Ver si pueden indentificar dónde hay pestaneos y movimientos oculares</li>\n",
    "    <li>Identificar los eventos en el plot (son lineas verticales de colores)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Los canales malos los vamos a descartar (_dropear_) más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado\n",
    "\n",
    "Ahora vamos a filtrar la data. Esto consiste en descartar las frecuencias que están por abajo o por encima de nuestro interés.\n",
    "Vamos a aplicar un filtro para todas las frecuencias por encima de 1Hz a esto se lo llama High-pass filter (filtro pasa altos) y todas las frecuencias por debajo de 40Hz Low-pass filter (filtro pasa bajos)\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Filtrar la data cruda entre 1Hz y 40Hz</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir valor high pass filter\n",
    "hpass = ...\n",
    "# definir valor low pass filter\n",
    "lpass = ...\n",
    "\n",
    "# filtrar data cruda\n",
    "# buscar en la documentacion\n",
    "# van a tener que utilizar el metodo de mne para filtrar la data \n",
    "raw_filtered = raw.filter(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a vamos realizar un gráfico de frecuencia (Power Spectral Density, PSD). Van a poder ver como por fuera de nuestros cortes (dado por los filtros) el poder de la señal cae. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filtered.plot_psd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir eventos\n",
    "Una vez que tenemos la data  filtrada el siguiente paso va a ser poder cortar nuestra data en épocas. O sea, vamos a tener que seleccionar eventos de interés (e.g.: estimulos, respuestas, etc) y luego cortar la data cruda alrededor de este evento. En este caso nuestros eventos van a ser los eventos presentados, ya sean go o no-go. Por ende, lo primero que vamos a hacer ahora es buscar estos eventos en la señal. Siempre que trabajamos con este tipo de señales va a ver un canal que esta destinado a marcar en que momento de la señal se presento el evento, y a estas marcas se las llama _triggers_. En el caso que haya que encontrar los eventos de un canal de estimulos vas a tener que usar la funcion mne.find_events()\n",
    "\n",
    "Para este dataset los estímulos ya fueron pasados a anotaciones en la señal.\\\n",
    "Pueden verlas ploteando la raw data. En este caso la función es mne.events_from_annotations()\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Encontrar eventos</li>\n",
    "    </ul>\n",
    "     <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Usar función mne.events_from_annotations()</i></li>\n",
    "    <li> <i>Esta función devuelve dos variables así que van a tener que dar dos variables para asignar (e.g. \"events\" y \"event_id\")</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar funcion events_from_annotations\n",
    "events, event_id = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funcion devuelve dos variables, en este caso \"events\" y \"event_id\".\\\n",
    "_Events_ contiene la informacion sobre todos los triggers (el primer número hace referencia al tiempo de presentación del evento en puntos de registro, mientras que el último número refiere al código asignado a cada tipo de evento).\\\n",
    "Y _event_id_ es un diccionario que contiene el id de cada evento con su nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events[:10]) #solo los 10 primeros eventos\n",
    "print(event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar los eventos\n",
    "mne.viz.plot_events(events, raw_filtered.info['sfreq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio los únicos eventos que nos van a interesar son los Go y No-Go. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Crear una lista con id de los eventos a incluir</li>\n",
    "    <li>Usar la funcion pick_events para seleccionar los eventos de interés</li>\n",
    "    <li>Crear un diccionario para los eventos y sus id a incluir</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Revisar el diccionario events_id para encontrar los id de cada evento</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista con los id de los eventos de interés (\"Go\" y \"No-Go\") \n",
    "include = ...\n",
    "\n",
    "# events to include using pick events\n",
    "events_included = mne.pick_events(...)\n",
    "\n",
    "# diccionario de eventos a incluir\n",
    "event_id_included  = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Épocas\n",
    "\n",
    "Ahora que ya tenemos los eventos identificados con sus IDs, podemos crear nuestras épocas alrededor de estos. \n",
    "De este modo, tenemos que definir desde qué tiempo hasta qué tiempo es la duración de cada una nuestras épocas (importante: el tiempo \"0\" corresponde a la referencia de la marca del evento). Además, hay que definir qué parte de la señal se utilizará como linea de base (_baseline_). Dicho baseline (que generalmente es un tiempo anterior a cada ensayo) sería restado a la señal epocheado, de forma tal de mitigar cambios en las señales de EEG que no estén relacioandas con la pregunta experimental.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Definir tiempo mínimo de época a los -200ms</li>\n",
    "    <li>Definir tiempo máximo de época a los 800ms</li>\n",
    "    <li>Definir baseline de -200ms a 0ms</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>El tiempo negativo indica que es anterior al evento.</i></li>\n",
    "    <li> <i>En mne el tiempo va en segundos no en milisegundos (ms)</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir tiempo minimo\n",
    "tmin = ...\n",
    "# definir tiempo maximo\n",
    "tmax = ...\n",
    "# definir baseline\n",
    "baseline = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que definimos los tiempos de las épocas ya podemos \"epoquear\" (i.e. extraer ventanas de interés de la señal continua de EEG). Los eventos que nos van a interesar para este análisis son solo los \"Go\" y \"No-Go\".\n",
    "\n",
    "Una parte muy importante del preprocesado es el descartar épocas malas. Normalmente es recomendable utilizar una combinación de algoritmos de detección de épocas malas e inspección visual de las épocas. En MNE podemos setear un criterio para _rejectear_ (descartar) las épocas que superan un determinado cierto umbral.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Epoquear la data cruda filtrada utilizando los tiempos predifinidos</li>\n",
    "    <li>Epoquear solo para los eventos Go y No-Go</li>\n",
    "    <li>Pasar a la función Epochs el criterio de rejecteo predifinido</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Vas a tener que usar la funcion mne.Epochs</i></li>\n",
    "    <li> <i>En mne el tiempo va en segundos no en milisegundos (ms)</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterio de rejecteo predifinido\n",
    "reject_criteria = dict(eeg= 200e-6, eog=200e-6) \n",
    "\n",
    "\n",
    "epochs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección visual de épocas\n",
    "\n",
    "Como dijimos, para _rejectear_ épocas se utiliza un critrio e inspección viusal. Previamente seteamos los criterio para _rejecteo_ y las marcamos al epoquear. En este caso toca realizar la inspección visual de las mismas.\n",
    "\n",
    "Para esto una vez ploteado van a ir scrolleando todas las épocas y marcando todas las que ustedes consideren malas. Al finalizar de scrollear todas, con ESC salen y se guardan las épocas que marcaron como malas y les va a indicar en base a que electrodos fueron marcadas (esto sirve por si ven que son todas por un solo electrodo podrían descartar el electrodo así no pierden tantas épocas)\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Realizar la inspección visual de todas las épocas</li>\n",
    "    <li>Marcar las épocas malas (en caso que existieran)</li>\n",
    "    <li>Marcar canales malos. En caso que todos los canales estuvieran bien, de todos modos seleccionar uno de los canales (haciendo click en el canal verán que se pone de un color gris mas claro) para que luego podamos practicar interpolar canales</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotear las épocas\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_bad()  # remover las epocas malas\n",
    "epochs.plot_drop_log() #plotear que épocas dropeamos y bajo que condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs) # ahora deberiamos tener tantas epocas menos como las que dropeamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar épocas\n",
    "Es conveniente ir guardando lo que vamos haciendo así no se pierde. Ahora que ya tenemos las épocas limpias vamos a guardarlas.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Guardar las épocas</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li>Utilizar el método \"save\" para guardar las épocas<i></i></li>\n",
    "    <li>El path en el que se guardarán las épocas es \"epochs_fname\"<i></i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_fname = bids_path.copy().update(suffix='epo', check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar el método `save` para guardar épocas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr directamente este bloque de código que permite identificar componentes que pudieran ser artefactos a través del método ICA\n",
    "\n",
    "n_components = 0.99  \n",
    "method = 'fastica'\n",
    "max_iter = 512 \n",
    "fit_params = dict(fastica_it=5)\n",
    "random_state = 42\n",
    "\n",
    "ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "                            method=method,\n",
    "                            max_iter=max_iter,\n",
    "                            random_state=random_state)\n",
    "\n",
    "ica.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a plotear primero las topologias para ver como son los componentes identificados. Los componentes oculares en general tienen un gran componente frontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components(inst = epochs, picks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para terminar de estar seguros estos artefactos eran oculares o cardíacos vamos a plotear las sources (i.e. fuentes) que nos muestra cómo se ven esos componentes en la señal. Hay que ver ahora si tienen forma de componente ocular o de cardíaco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(epochs, block=False, picks =range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolar canales malos\n",
    "\n",
    "Ahora vamos a interpolar los canales que a lo largo del preprocesamiento fuimos marcando como malos. Esto significa que vamos a tratar de recrear estos canales a partir de la información de los canales vecinos. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Interpolar canales malos</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Usar el método interpolate_bads()</i></li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs interpolated\n",
    "epochs.load_data()\n",
    "epochs_interpolate = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rereferenceo a _grand average_ de los electrodos\n",
    "\n",
    "Los distintos sistemas de EEG utilizan diferentes referencias para calcular los voltajes. Por ejemplo, una referencia puede ser electrodos en los mastoides, en los lóbulos de las orejas o a algun electrodo del cuero cabelludo. Por esto mismo es un standard aplicar un \"rereferenceo\" en algún punto del preprocesado. En este caso vamos a rereferencear al promedio de todos los electrodos.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li>Rereferencear a el promedio de todos los electrodos</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>Usar función set_eeg_reference</i></li>\n",
    "    <li> <i>Tener en cuenta que esta función devuelve dos instancias así que hay que darle dos variables</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar average para la referencia de los canales\n",
    "epochs_rereferenced, ref_data = mne.set_eeg_reference(inst = ..., ref_channels = '...', copy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear Evoked\n",
    "\n",
    "Luego de concluir los pasos de pre-procesamiento podemos dedicarnos ahora a responder una pregunta concreta de investigación:\n",
    "¿Es posible encontrar diferencias en el procesamiento cerebral de condiciones Go y No-Go?\n",
    "Particularmente, el potencial relacionado con evento (ERP, según su sigla en inglés) que nos interesa ver es el P300. Este es un potencial que se ve generalmente en electrodos centro-posteriores alrededor de los 300ms, y se lo ha estudiado previamente como correlato en tareas Go/No-go.\n",
    "\n",
    "De este modo, ahora vamos a poder calcular el Evoked, o sea el promedio de los distintos ensayos para cada una de las condiciones por separado.\n",
    "\n",
    "Esto puede ser realizado para cada electrodo por separado, se pueden realizar cluster de electrodos o general un solo promedio de todos los electrodos.\n",
    "\n",
    "Primero empecemos calculando el Evoked para cada electrodo por separado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_rereferenced[\"go\"].average().plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómputo de Evoked para la condición No-Go\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora calculemos el Evoked para el promedio de los electrodos para cada condición\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li> Crearemos una variable llamada \"average_go\" en la que calcularemos el promedio (\"average()\") de las epocas rereferenciadas especificamente para la condición Go. </li>\n",
    "    <li> Crearemos una variable llamada \"average_no_go\" en la que calcularemos el promedio (\"average()\") de las epocas rereferenciadas especificamente para la condición No-Go. </li>\n",
    "    <li> Realizamos la compración entre los ERPs de la condición Go y No-Go </li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>tips</i>:\n",
    "    <ul>\n",
    "    <li> <i>La función \"mne.viz.plot_compare_evokeds\" sirve para comparar ERPs</i></li>\n",
    "    <li> <i>Es importante asignar como argumento de dicha función un diccionario que incluya average_go y average_no_go</i></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_go = epochs_rereferenced[\"go\"].average()\n",
    "average_no_go = ...\n",
    "# Comparamos ERPs\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizar Regiones de Interés (ROIs): promedio entre canales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a realizar 2 clusters de 6 electrodos.\\\n",
    " Vamos a generar un **cluster frontal** (los 6 electrodos alrededor de Fz) y un **cluster posterior** (los 6 electrodos alrededor de Pz).\n",
    "\n",
    " <div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>:\n",
    "     <ul>\n",
    "    <li> En las variables \"frontal\" y \"posterior\" crearemos listas donde que pondrán los canales que correpsonden a cada cluster. </li>\n",
    "    <li> Al momento de comparar ERPs, esta vez pasaremos como argumento \"picks\" las listas de canales creadas (i.e. frontal y posterior). De esta forma podremos subsetear según ROIs </li>\n",
    "    </ul>\n",
    "    <br>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal = ...\n",
    "posterior = ...\n",
    "\n",
    "evokeds = dict(Go=list(epochs_rereferenced['go'].iter_evoked()),\n",
    "               ...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks=frontal, combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks=posterior, combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta acá estuvimos haciendo análisis \"clásicos\" de EEG, a partir de los cuales intentamos caracterizar la respuesta cerebral de los participantes de acuerdo a lo estímulos visuales que se le presentaron (cue 'Go' o 'No-Go').\n",
    "\n",
    "Ahora vamos a hacer lo opuesto. Vamos a intentar **decodificar** (i.e. clasificar de forma automática) qué estímulo vio el participante a partir de sus señales cerebrales. Esto se lo conoce como *Decoding*.\n",
    "\n",
    "De este modo, vamos a hacer una clasificación binaria (cue 'Go' vs. 'No-Go') utilizando algoritmos clásicos de la librería [Scikit-Learn](https://scikit-learn.org/stable/), e.g. Regresión Logística, SVM y Random Forestest. Con este fin podríamos utilizar también Deep Learning.\\\n",
    "Para este ejercicio vamos a uitilizar el algoritmo [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random+forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar con la práctica de *Decoding*, vamos a importar los módulos necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler, Vectorizer, cross_val_multiscore)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de haber importado los módulos necesarios, el primer paso es armar las matrices de datos para el clasificador.\\\n",
    "Para esto no vamos computar *features*, sino que vamos a utilizar directamente la data prepreocesada (limpia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs_rereferenced.get_data()  # EEG signals: n_epochs, n_eeg_channels, n_times\n",
    "y = epochs_rereferenced.events[:, 2]  # target: go vs nogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de *Pipeline* de clasificación\n",
    "\n",
    "La clase [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) de scikit-learn nos permite aplicar una serie de transformaciones a un conjunto de datos, y al final aplicar un estimador.\n",
    "\n",
    "La primera de estas transformaciones a aplicar en nuestros datos será una estandarización a través de 'Scaler'. Luego, el segundo paso será vectorizar ('Vectorizer'), el cual nos permite que nuestra matriz de features X (en nuestro caso una unica variable con los datos limpios y preprocesados de EEG) sea utilizable dentro de Scikit-learn.\n",
    "\n",
    "Finalmente, como último paso, seteamos el algoritmo de clasificación a utilizar. En este caso, el algoritmo será Random Forest. \n",
    "\n",
    "*Nota 1:* Si bien es una buena practica optimizar hiperparámetros del algortimo para buscar una mejor performance del modelo, en este caso se utilizará la configuración de hiperparámetros por default del mismo.\n",
    "\n",
    "*Nota 2:* Se podría aplicar también otros pasos intermedios en el Pipeline. Por ejemplo, para reducir la dimensionalidad de la matriz de features (previo a aplicar el estimador) con métodos como Analisis de Componentes Principales (PCA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(\n",
    "    Scaler(epochs_rereferenced.info, scalings='mean'),\n",
    "    Vectorizer(),\n",
    "    RandomForestClassifier(random_state = 42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada\n",
    "\n",
    "Luego, para evitar subre ajuste (*over-fitting*) vamos a utilizar [K-fold cross-validation](https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/DeepLearning/5_Evaluacion_Modelos/2_Seleccion_Modelos.ipynb#scrollTo=Rx7BgvZndOmD).\n",
    "\n",
    "Con este fin MNE ya nos provee de un método para realizar la validación cruzada y obtener además una performance: [cross_val_multiscore](https://mne.tools/dev/generated/mne.decoding.cross_val_multiscore.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos a implementar el modelo  y obtener la perfromance de clasificación en validación cruzada.\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>: Agregar a la funcion cross_val_multiscore los parametros relacionados al estimador, la matriz de features y el vector de labels. </li>\n",
    "    </ul>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_multiscore(... , ... , ..., cv=5, n_jobs=1, scoring = 'roc_auc')\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "score = np.mean(scores, axis=0)\n",
    "print('Clasificacion AUC: %0.1f%%' % (100 * score,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio (teórico)</b>:\n",
    "     <ul>\n",
    "    <li>¿Cómo interpretamos este resultado?</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>Considerar</i>:\n",
    "    <ul>\n",
    "    <li> Performance obtenida\n",
    "</li>\n",
    "    <li> Cantidad de clases en la clasificación\n",
    "</li>\n",
    "    <li> Métrica de performance utilizada\n",
    "</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Test de Permutaciones\n",
    "\n",
    "¿Cómo sabemos si la clasificación obtenida es significativa o es producto del azar?\n",
    "Una forma de testear esto es volver a correr nuestro clasificador muchas veces (e.g. 1000 veces), pero con las etiquetas de 'Go' y 'No Go' mezcladas. Luego, tenemos que ver si *nuestro* clasificador original tiene una mejor performance que la mayor parte (>95%) de los clasificadores \"random\" que generamos.\n",
    "A esto se lo conoce como Test de Permutaciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio</b>: Hacer un test de permutaciones para evaluar si la performance de nuestro modelo fue significativa\n",
    "     <ul>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <i>Tips</i>:\n",
    "    <ul>\n",
    "    <li>Utilizar la función [permutation_test_score()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html) </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolver ejercicio de Test de Permutaciones\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extra:** Temporal Decoding\n",
    "Al realizar decoding con EEG, nuestro interés no es únicamente  encontrar un modelo que maximice la performance en la tarea, sino también mejorar la comprensión teórica del fenómeno a estudiar.\n",
    "\n",
    "De este modo, una pregunta que podemos hacernos **es qué momento** de la presentación del estimulo, nuestro clasificador logra distintuir entre ambas etiquetas por encima del azar. \n",
    "\n",
    "Se conoce como *Temporal Decoding* a implementar un clasificador y testearlo para cada punto del tiempo, para poder observar así cómo varía en el tiempo la perfromance de nuestro clasificador.\n",
    "Así, el primer momento en qué el clasificador se diferencia del azar podría explicar en qué momento nuestro sistema nervioso diferencia entre ambos tipos de estímulos.\n",
    "\n",
    "Para poder hacer Temporal Decoding, vamos a utilizar la función [SlidingEstimator](https://mne.tools/dev/generated/mne.decoding.SlidingEstimator.html) de MNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc', verbose=True)\n",
    "\n",
    "# Acá usamos cv=3 por una cuestión de velocidad. \n",
    "scores_cv = cross_val_multiscore(time_decod, X, y, cv=3, n_jobs=1)\n",
    "\n",
    "# Calculamos la media a través de las CrossValidation scores\n",
    "scores = np.mean(scores_cv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extra 2:** Temporal Generalization\n",
    "\n",
    "¡Felicitaciones! Juntxs pudimos hacer Temporal Decoding.\n",
    "\n",
    "Sin embargo, otra pregunta qué nos surgió es qué tanto se puede generalizar esa decodificación temporal.\n",
    "\n",
    "En concreto, ¿La predicción en el punto n, qué tanto generaliza para la predicción del punto n+1, n+2, ..., n+m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Temporal generalization object\n",
    "time_gen = GeneralizingEstimator(clf, n_jobs=1, scoring='roc_auc',\n",
    "                                 verbose=True)\n",
    "\n",
    "# again, cv=3 just for speed\n",
    "scores = cross_val_multiscore(time_gen, X, y, cv=3, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot the diagonal (it's exactly the same as the time-by-time decoding above)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, np.diag(scores), label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Decoding MEG sensors over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(scores, interpolation='lanczos', origin='lower', cmap='RdBu_r',\n",
    "               extent=epochs.times[[0, -1, 0, -1]], vmin=0., vmax=1.)\n",
    "ax.set_xlabel('Testing Time (s)')\n",
    "ax.set_ylabel('Training Time (s)')\n",
    "ax.set_title('Temporal generalization')\n",
    "ax.axvline(0, color='k')\n",
    "ax.axhline(0, color='k')\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FIN**\n",
    "\n",
    "¡Hemos llegado al final de este tutorial!\n",
    "\n",
    "Es importante remarcar que esto fue hecho para **un solo sujeto**. \n",
    "En caso de querer evaluar inter-sujeto sería necesario hacer los análisis con todos los participantes juntos para ganar poder estadístico y mejorar la performance de nuestros clasificadores.\n",
    "\n",
    "*¿Creen que podrían entrenar un modelo inter-sujeto?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "75d28a4c943af93f3c5ef0051379ef23950f7970d3ac2d16d44be87ff6751af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
